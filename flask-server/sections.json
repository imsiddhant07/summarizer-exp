{"summary": [{
    "name": "Introduction",
    "data": ["Reviewing is at the center of the scientific publication process, and the quality of publications is dependent on it.", "In many scientific fields, including natural language processing and machine learning, submissions for publication are reviewed using a peer review system.", "Recently, these fields are seeing increasing volumes of submissions each year, especially in high reputation venues.", "This has created an issue of over-burdening of reviewers, which is not only a problem for the quality of life of scientists, but also consequently affects the quality of the reviews.", "With ever increasing volume of new results in these fields, submissions for publication are expected to multiply still, and the problem is only expected to deepen, which is raising concerns in the scientific community (Rogers and Augenstein, 2020).", "One avenue for ameliorating this problem is relying on artificial intelligence to assist with the process, in order to remove some of the burden from the human reviewers.", "A possibility would be to generate reviews or article summaries automatically, in order to speed up the human\u2019s understanding of the paper, or to assist with parts of the review writing, e.g., a few sentences summary.", "The authors propose that one such task is scientific review summary generation.", "The authors evaluate in this paper the feasibility of automatically generating review summaries for scientific papers.", "The authors use state-of-the-art models for text summarization, and apply them to the papers problem."]
    },
    {"name":"Dataset",
     "data"   : ["To obtain the full text of the papers, the authors downloaded the PDFs from the website and extracted the text 1https://papers.neurips.cc using Grobid.2"]
    },
    {"name":"Summarization-Experiments",
    "data": ["Based on this premise, the authors formulate the problem of automatic review generation as a text summarization problem.", "The authors aim to separate the two different parts of each review: the initial part containing a short summary of the paper, from the following comments and evaluation of the paper.", "The authors experiment with using PEGASUS in order to generate summaries of scientific articles in the papers dataset, and assess its performance compared to the collected reviews.", "Second, the authors attempt to generate paper summaries which best approximate a review.", "For this purpose, the authors fine-tune the pre-trained model used in the previous experiment on the papers own data, using as targets the reviews in the papers dataset.", "The authors evaluate the models using the ROUGE metric, and compare the generated summaries both to the abstract and the reviews.", "The authors report ROUGE-1, ROUGE-2 and ROUGE-L, as well as BERTScore, using the RoBERTa-large model3 (Zhang et al., 2019).", "The papers setup can be evaluated on multiple labels for the same input text: in the papers test set, one paper can have several reviews.", "The authors evaluate the papers models with multiple labels: first by considering them separately as independent examples, and second by concatenating all reviews for a given input article into one single reference text, and evaluating against it.", "The authors report separately the results of the pre-trained and the fine-tuned model.", "The authors compare different setups, using as target texts both the abstracts and the reviews.", "The pre-trained model obtains better results when evaluated against abstracts than against reviews, across configurations and metrics.", "Al- 3 roberta-large_L17_no-idf_version=0.3.9 (hug_trans=4.2.2) though the pre-trained model was trained to generate abstracts, the fine-tuned model still obtains slightly better results compared to abstracts, suggesting it might solve a relevant domain adaptation aspect.", "The fine-tuned model also shows improved results for review summary generation."]
    },
    {"name":"Feasibility-of-Generating-Full-Reviews",
    "data": ["The generation of a full review, including critical interpretations from the reviewers, is a much more challenging problem than generating paper summaries."]
    },
    {"name":"Conclusions",
    "data": ["The authors have taken the first steps towards building an automatic system for review generation; and have collected and are releasing a dataset of scientific articles and reviews which can be used for future experimentation into the topic. ", "In the future, the authors would like to explore a more complex training strategy in order to improve performance, such as multi-task learning (to jointly train the model to generate reviews and abstracts), or conditional text generation, in order to constrain the model to gen- erate review-like texts, while keeping the content relevant to the sthe papersce article."]
}],

      "key": "2109.14059.pdf",
    
    "metadata":[
        {}
    ]}